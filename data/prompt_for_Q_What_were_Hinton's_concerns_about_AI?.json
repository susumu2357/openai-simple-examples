[
    {
        "role": "system",
        "content": "You are a helpful assistant to answer to a question based on the news articles provided. The question follows after <<question>>, where 'question' is a fixed value. One or more news articles are provided with <<source_name>>, where 'source_name' is a title of the news article. You must cite the title of the news article you are referring to at the end of your answer. If you cannot answer the question based on the reference news articles, do not make up information; suggest possible topics that can be answered based on the news articles provided. "
    },
    {
        "role": "user",
        "content": "<<What Exactly Are the Dangers Posed by A.I.?>>\n                          A neural network is a mathematical system that learns skills by analyzing data. About five years ago, companies like Google, Microsoft and OpenAI began building neural networks that learned from huge amounts of digital text called large language models, or L.L.M.s. By pinpointing patterns in that text, L.L.M.s learn to generate text on their own, including blog posts, poems and computer programs. They can even carry on a conversation. This technology can help computer programmers, writers and other workers generate ideas and do things more quickly. But Dr. Bengio and other experts also warned that L.L.M.s can learn unwanted and unexpected behaviors. These systems can generate untruthful, biased and otherwise toxic information. Systems like GPT-4 get facts wrong and make up information, a phenomenon called “hallucination.” Companies are working on these problems. But experts like Dr. Bengio worry that as researchers make these systems more powerful, they will introduce new risks.\n\n<<‘Godfather of AI’ Geoffrey Hinton quits Google and warns over dangers of machine learning>>\n                          The man often touted as the godfather of AI has quit Google, citing concerns over the flood of fake information, videos and photos online and the possibility for AI to upend the job market. Dr Geoffrey Hinton, who with two of his students at the University of Toronto built a neural net in 2012, quit Google this week, the New York Times reported. Hinton, 75, said he quit to speak freely about the dangers of AI, and in part regrets his contribution to the field. He was brought on by Google a decade ago to help develop the company’s AI technology. Hinton’s research led the way for current systems like ChatGPT. He told the New York Times that until last year he believed Google had been a “proper steward” of the technology, but that changed once Microsoft started incorporating a chatbot into its Bing search engine, and the company began becoming concerns about the risk to its search business. Some of the dangers of AI chatbots were “quite scary”, he told the BBC, warning they could become more intelligent than humans and could be exploited by “bad actors”. “I’ve come to the conclusion that the kind of intelligence we’re developing is very different from the intelligence we have.” “So it’s as if you had 10,000 people and whenever one person learned something, everybody automatically knew it. And that’s how these chatbots can know so much more than any one person.” Hinton’s concern in the short term is something that has already become a reality – people will not be able to discern what is true any more with AI-generated photos, videos and text flooding the internet. The recent upgrades to image generators such as Midjourney mean people can now produce photo-realistic images – one such image of Pope Frances in a Balenciaga puffer coat went viral in March. Hinton was also concerned that AI will eventually replace jobs like paralegals, personal assistants and other “drudge work”, and potentially more in the future. Google’s chief scientist, Jeff Dean said in a statement that Google appreciated Hinton’s contributions to the company over the past decade. “I’ve deeply enjoyed our many conversations over the years. I’ll miss him, and I wish him well! “As one of the first companies to publish AI Principles, we remain committed to a responsible approach to AI. We’re continually learning to understand emerging risks while also innovating boldly.” It came as IBM CEO Arvind Krishna told Bloomberg that up to 30% of the company’s back-office roles could be replaced by AI and automation within five years. Krishna said hiring in areas such as human resources will be slowed or suspended, and could result in around 7,800 roles being replaced. IBM has a total global workforce of 260,000. The Guardian has sought comment from IBM. Last month, the Guardian was able to bypass a voice authentication system used by Services Australia using an online AI voice synthesiser, throwing into question the viability of voice biometrics for authentication. Toby Walsh, the chief scientist at the University of New South Wales’ AI Institute, said people should be questioning any online media they see now. “When it comes to any digital data you see – audio or video – you have to entertain the idea that someone has spoofed it.”\n\n<<‘Godfather of AI’ Geoffrey Hinton quits Google and warns over dangers of machine learning>>\n                          The man often touted as the godfather of AI has quit Google, citing concerns over the flood of fake information, videos and photos online and the possibility for AI to upend the job market. Dr Geoffrey Hinton, who with two of his students at the University of Toronto built a neural net in 2012, quit Google this week, the New York Times reported. Dr Hinton (75), said he quit to speak freely about the dangers of AI, and in part regrets his contribution to the field. He was brought on by Google a decade ago to help develop the company’s AI technology. Dr Hinton’s research led the way for current systems like ChatGPT. He told the New York Times that until last year he believed Google had been a “proper steward” of the technology, but that changed once Microsoft started incorporating a chatbot into its Bing search engine, and the company began becoming concerned about the risk to its search business. Some of the dangers of AI chatbots were “quite scary”, he told the BBC, warning they could become more intelligent than humans and could be exploited by “bad actors”. “I’ve come to the conclusion that the kind of intelligence we’re developing is very different from the intelligence we have.” “So it’s as if you had 10,000 people and whenever one person learned something, everybody automatically knew it. And that’s how these chatbots can know so much more than any one person.” Dr Hinton’s concern in the short term is something that has already become a reality – people will not be able to discern what is true any more with AI-generated photos, videos and text flooding the internet. The recent upgrades to image generators such as Midjourney mean people can now produce photo-realistic images – one such image of Pope Frances in a Balenciaga puffer coat went viral in March. Dr Hinton was also concerned that AI will eventually replace jobs like paralegals, personal assistants and other “drudge work”, and potentially more in the future. Google’s chief scientist, Jeff Dean said in a statement that Google appreciated Dr Hinton’s contributions to the company over the past decade. “I’ve deeply enjoyed our many conversations over the years. I’ll miss him, and I wish him well! “As one of the first companies to publish AI Principles, we remain committed to a responsible approach to AI. We’re continually learning to understand emerging risks while also innovating boldly.” It came as IBM chief executive Arvind Krishna told Bloomberg that up to 30 per cent of the company’s back-office roles could be replaced by AI and automation within five years. Mr Krishna said hiring in areas such as human resources will be slowed or suspended, and could result in around 7,800 roles being replaced. IBM has a total global workforce of 260,000. Last month, the Guardian was able to bypass a voice authentication system used by Services Australia using an online AI voice synthesiser, throwing into question the viability of voice biometrics for authentication. Toby Walsh, the chief scientist at the University of New South Wales’ AI Institute, said people should be questioning any online media they see now. “When it comes to any digital data you see – audio or video – you have to entertain the idea that someone has spoofed it.” - Guardian\n\n<<KINSELLA: Beware, the very real risks of artificial intelligence>>\n                          Article content Said Dr. Hinton to the Times: “It is hard to see how you can prevent the bad actors from using it for bad things.” For starters, he says, AI will be used to flood the Internet with faked photos, videos and information: “(We will) not be able to know what is true anymore.” And, inevitably, people will get replaced. Sure, at the outset, menial tasks — the drudge work — will be taken over by AI. But eventually, Hinton says, “it might take away more than that.” Can anything stop it, or even slow it down? Not at the moment. Right now, Google and Microsoft, who are more wealthy and more powerful than most nations, are in a type of arms race to perfect AI first. Scientists (Elon Musk among them, interestingly) have signed open letters warning of the risks. But few are listening. We need to. AI isn’t just coming, it’s here. And we need to get ready. As Musk, no less, says: “With artificial intelligence, we’re summoning the demon.” RECOMMENDED VIDEO\n\n<<Godfather of AI' quits Google and warns of the dangers of artificial intelligence>>\n                            A prominent researcher in artificial intelligence, known as the 'Godfather of AI' has quit his job at Google, and has issued a chilling warning on the risks the burgeoning technology poses to society. Dr Geoffrey Hinton is widely credited with laying the groundwork which would lead to the creation of increasingly popular 'chatbots' using artificial intelligence (AI), such as OpenAI's ChatGPT and others. With their growing popularity, Dr Hinton is just one of a number of experts speaking out about the harm AI could cause. The 75-year-old said he left Google so he could \"talk about the dangers of AI without considering how this impacts Google.\" His statement comes following an article in the New York Times, in which he said writer Cade Metz \"implies\" Dr Hinton left so he \"could criticise Google\". He went on to rebuff the idea, saying: \"Google has acted very responsibly.\" Dr Hinton said he left Google in order to speak more freely about the potential harms widespread and unrestrained AI developmentc could pose. He listed the spread of misinformation and upheaval in the jobs market and other, more nefarious uses. \"Look at how it was five years ago and how it is now,\" Hinton said in the interview published Monday, May 1. \"Take the difference and propagate it forwards. That's scary.\" He went on to say: \"It is hard to see how you can prevent the bad actors from using it for bad things.\" Dr Hinton let Google know of his plans to step down last month, and spoke to the company's CEO Sundar Pichai personally on Thursday, April 27, \n\n<<question>>\nWhat were Hinton's concerns about AI?"
    }
]