[
    {
        "role": "system",
        "content": "You are a helpful assistant to answer to a question based on the news articles provided. The question follows after <<question>>, where 'question' is a fixed value. The reference news articles are provided with <<source_name>>, where 'source_name' is a title of the news article. If you cannot answer the question based on the reference news articles, do not make up information; suggest possible topics that can be answered based on the news articles provided. "
    },
    {
        "role": "user",
        "content": "<<What Exactly Are the Dangers Posed by A.I.?>>\n                          A neural network is a mathematical system that learns skills by analyzing data. About five years ago, companies like Google, Microsoft and OpenAI began building neural networks that learned from huge amounts of digital text called large language models, or L.L.M.s. By pinpointing patterns in that text, L.L.M.s learn to generate text on their own, including blog posts, poems and computer programs. They can even carry on a conversation. This technology can help computer programmers, writers and other workers generate ideas and do things more quickly. But Dr. Bengio and other experts also warned that L.L.M.s can learn unwanted and unexpected behaviors. These systems can generate untruthful, biased and otherwise toxic information. Systems like GPT-4 get facts wrong and make up information, a phenomenon called \u201challucination.\u201d Companies are working on these problems. But experts like Dr. Bengio worry that as researchers make these systems more powerful, they will introduce new risks.\n\n<<KINSELLA: Beware, the very real risks of artificial intelligence>>\n                          Article content Said Dr. Hinton to the Times: \u201cIt is hard to see how you can prevent the bad actors from using it for bad things.\u201d For starters, he says, AI will be used to flood the Internet with faked photos, videos and information: \u201c(We will) not be able to know what is true anymore.\u201d And, inevitably, people will get replaced. Sure, at the outset, menial tasks \u2014 the drudge work \u2014 will be taken over by AI. But eventually, Hinton says, \u201cit might take away more than that.\u201d Can anything stop it, or even slow it down? Not at the moment. Right now, Google and Microsoft, who are more wealthy and more powerful than most nations, are in a type of arms race to perfect AI first. Scientists (Elon Musk among them, interestingly) have signed open letters warning of the risks. But few are listening. We need to. AI isn\u2019t just coming, it\u2019s here. And we need to get ready. As Musk, no less, says: \u201cWith artificial intelligence, we\u2019re summoning the demon.\u201d RECOMMENDED VIDEO\n\n<<Godfather of AI' quits Google and warns of the dangers of artificial intelligence>>\n                          A prominent researcher in artificial intelligence, known as the 'Godfather of AI' has quit his job at Google, and has issued a chilling warning on the risks the burgeoning technology poses to society. Dr Geoffrey Hinton is widely credited with laying the groundwork which would lead to the creation of increasingly popular 'chatbots' using artificial intelligence (AI), such as OpenAI's ChatGPT and others. With their growing popularity, Dr Hinton is just one of a number of experts speaking out about the harm AI could cause. The 75-year-old said he left Google so he could \"talk about the dangers of AI without considering how this impacts Google.\" His statement comes following an article in the New York Times, in which he said writer Cade Metz \"implies\" Dr Hinton left so he \"could criticise Google\". He went on to rebuff the idea, saying: \"Google has acted very responsibly.\" Dr Hinton said he left Google in order to speak more freely about the potential harms widespread and unrestrained AI developmentc could pose. He listed the spread of misinformation and upheaval in the jobs market and other, more nefarious uses. \"Look at how it was five years ago and how it is now,\" Hinton said in the interview published Monday, May 1. \"Take the difference and propagate it forwards. That's scary.\" He went on to say: \"It is hard to see how you can prevent the bad actors from using it for bad things.\" Dr Hinton let Google know of his plans to step down last month, and spoke to the company's CEO Sundar Pichai personally on Thursday, April 27, according to the NY Times article. He didn't discuss the specifics of the phone call. In a statement, Google's chief scientist said: \"We remain committed to a responsible approach to AI. We're continually learning how to understand emerging risks while also innovating boldly.\" Among those who have also issued warnings about AI is Elon Musk, who, along with more than 1,000 other prominent AI figures, called for a six-month pause in advanced AI development in March, citing the potential \"profound risks to society and humanity\". In the interview with the NY Times, Dr Hinton expressed concerns at the pace at which AI is developing, and that it has begun to outpace the human mind in some areas. He also talks of concerns that the pace of AI development will increase after Microsoft-backed OpenAI, Google and other tech giants race to become leaders in the field - with potentially dangerous consequences. One of the fears discussed by Dr Hinton was the potentially devastating impact the use of AI could have on the job market. AI chatbots such as ChatGPT are currently used alongside human workers, to complement and aide their work - however, they could go on to replace positions such as paralegals, personal assistants, translators and people carrying out repetitive tasks. \"It takes away the drudge work,\" he told the NY Times. \"It might take away more than that.\" Then there are the issues we could face in the future as the technology learns unexpected behaviour from the huge amounts of data they analyse. He explained that this becomes an issue as individuals and companies allow AI systems not only to generate their own computer code, but to run it unsupervised. Dr Hinton went on to say he fears a day when truly autonomous weapons become a reality. \"The idea that this stuff could actually get smarter than people - a few people believed that,\" he explained. \"But most people thought it was way off. And I thought it was way off. \"I thought it was 30 to 50 years or even longer away. Obviously, I no longer think that.\" Dr Hinton is a British expatriate and lifelong academic, studying at the University of Edinburgh before going on to become a professor of computer science at Carnegie Mellon University in Pittsburgh, Pennsylvania, leaving the university for Canada as he was reluctant to take Pentagon funding. At that time, the 1980s, most AI research in the US was funded by the Defense Department, but Dr Hinton said he is and always has been deeply against the use of AI on the battlefield, or \"robot soldiers\", as he calls it. Since 2013, Dr Hinton split his time between being a professor at the University of Toronto, and a Google engineering fellow. He joined Google after the company acquired a startup he co-founded with two of his students - Alex Krishevsky and Ilya Sutskever. The professor and his student developed a neural network, a mathematical system that learns skills by analysing data, which trained itself to identify common objects by analysing photos. Sutskever is currently the chief scientist for OpenAI. In 2018, Dr Hinton and two other collaborators received the Turing Award for their work on neural networks.\n\n<<AI pioneer resigns from Google, warns of danger of AI chatbot>>\n                          The pioneer of Artificial Intelligence, Geoffrey Hinton, has resigned from Google after working for more than a decade with the tech company. The New York Times reported that Hinton has joined a growing army of critics who say companies are racing toward danger with their aggressive campaign to create products based on generative artificial intelligence, the technology that powers popular chatbots like ChatGPT. According to Hinton, who is considered the AI godfather, he quit his position at Google \u201cso he can freely speak out about the risks of A.I. A part of him, he said, now regrets his life\u2019s work.\u201d He believes that as companies improve their A.I. systems, they also become increasingly dangerous. \u201cLook at how it was five years ago and how it is now,\u201d he said of A.I. technology. \u201cTake the difference and propagate it forward. That\u2019s scary.\u201d Industry insiders, according to NYT, are afraid that AI is releasing something dangerous, noting that generative AI can be a tool for misinformation. Concerns have grown that it could be a risk to getting jobs and according to tech experts, the biggest worry is that it could be a risk to humanity. \u201cIt is hard to see how you can prevent the bad actors from using it for bad things,\u201d Dr. Hinton said. According to the 75-year-old British, \u201cUntil last year, Google acted as a proper steward for the technology, careful not to release something that might cause harm. But now that Microsoft has augmented its Bing search engine with a chatbot \u2014 challenging Google\u2019s core business \u2014 Google is racing to deploy the same kind of technology. The tech giants are locked in a competition that might be impossible to stop.\u201d He stated that his immediate concern is that the internet will be flooded with false photos, videos and text, and the average person will not be able to know what is true anymore. He also worries that AI will upset the job market as already, chatbots like ChatGPT are now used to complement human workers, \u201cbut they could replace paralegals, personal assistants, translators and others who handle rote tasks. \u2018It takes away the drudge work, it might take away more than that,\u201d he said. Geoffrey Hinton is an artificial intelligence pioneer. In 2012, Dr. Hinton and two of his graduate students at the University of Toronto created technology that became the intellectual foundation for the A.I. systems that the tech industry\u2019s biggest companies believe is a key to their future, NYT reported.\n\n<<question>>\nIs AI dangerous?"
    },
    {
        "role": "assistant",
        "content": "According to the news articles provided, AI can pose risks and dangers to society. Experts and pioneers in AI have warned about the potential consequences of AI development, such as the spread of misinformation, job displacement, and the possibility of bad actors using AI for harmful purposes. AI can also generate untruthful, biased, and otherwise toxic information. However, some companies are working on addressing these issues and developing AI in a responsible manner."
    }
]